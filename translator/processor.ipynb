{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import config\n",
    "l = 0\n",
    "d = {}\n",
    "filename = config.hny[\"frmpapname\"]\n",
    "with open(f\"data/hny/{filename}\") as fileobject:\n",
    "    for line in fileobject:\n",
    "        l += 1\n",
    "        if config.hny[\"sep\"] not in line:\n",
    "            continue\n",
    "        if l >= config.hny[\"startline\"]:\n",
    "            word, definition = line.split(config.hny[\"sep\"], 1)\n",
    "            # word, _, definition = line.rpartition(config.hny[\"sep\"])\n",
    "            word = word.strip()[1:]\n",
    "            definition = definition.strip()\n",
    "\n",
    "            if word in config.hny[\"correction\"]:\n",
    "                definition = config.hny[\"correction\"][word]\n",
    "            d[word] = definition\n",
    "df = pd.DataFrame.from_dict(d, orient=\"index\", columns=[\"nl\"])\n",
    "df.index.name = \"pap\"\n",
    "df = df.reset_index()\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractFirstWord(row, lan):\n",
    "    raw_pap = row[\"pap\"]\n",
    "    raw_nl = row[\"nl\"]\n",
    "    raw = row[lan]\n",
    "\n",
    "    # Remove tags\n",
    "    without_tags = re.sub('[\\(\\[{<].*?[\\)\\]}>]', \"\", raw)\n",
    "\n",
    "    # Remove numbers\n",
    "    without_num = re.sub('[0-9][\\.:]', \"\", without_tags)\n",
    "\n",
    "    without_num = without_num.strip()\n",
    "\n",
    "    # Only do match if there is a special character, facilitates match until reaching the character\n",
    "    if re.findall(r'[;\\.,!\\(]+',without_num):\n",
    "        match = re.findall(r'^(.*?)[;\\.,!\\(].*',without_num)        \n",
    "\n",
    "        # Select first match\n",
    "        match = match[0]\n",
    "    else:\n",
    "        match = without_num\n",
    "    \n",
    "    # Remove stray characters\n",
    "    match = re.sub('[\\(\\)\\]]', \"\", match)\n",
    "\n",
    "    # Remove spaces and make everything lowercase\n",
    "    match = match.strip().lower()\n",
    "\n",
    "    # Check if there are characters with non letters\n",
    "    if not all(x.isalpha() or x.isspace() for x in match):\n",
    "        print(f\"Without tags/num was:{without_num}\")\n",
    "        print(f\"pap:{raw_pap}|cleaned:{match}|nl:{raw_nl} is not letters\")\n",
    "    \n",
    "    # if len(match) > 21:\n",
    "    #     print(f\"long word:{match}|raw:{raw}\")\n",
    "\n",
    "    return match\n",
    "\n",
    "# Drop empty rows\n",
    "print(f\"Length before dropping n/a: {len(df)}\")\n",
    "df['pap'].replace('', pd.np.nan, inplace=True)\n",
    "df.dropna(subset=[\"pap\"], inplace=True)\n",
    "print(f\"Length after dropping n/a: {len(df)}\")\n",
    "\n",
    "# Process simple version of words\n",
    "df[\"nl-simple\"] = df.apply(lambda row: extractFirstWord(row, \"nl\"), axis=1)\n",
    "df[\"pap-simple\"] = df.apply(lambda row: extractFirstWord(row, \"pap\"), axis=1)\n",
    "df.set_index(\"pap-simple\", inplace=True)\n",
    "\n",
    "# Save to file\n",
    "df.to_csv(\"data/hny/pap-nl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"ami ta bai kas\"\n",
    "sentence2 = \"mi stima mi yu-homber\"\n",
    "sentence3 = \"ami ta kòre outo\"\n",
    "sentence4 = \"mi no kier bai skol\"\n",
    "sentence5 = \"mi no kier kumpra bo kacho\"\n",
    "sentence6 = \"e ta hopi grandi\"  \n",
    "sentence7 = \"ami ta bai kas anto despues bini bek\"\n",
    "translation = \"\"\n",
    "# print(df.loc[\"ta\"])\n",
    "# Try to ignore accents if the word isn't there\n",
    "# Consider and extract synonyms\n",
    "# Extract more from other way around\n",
    "for sentence in [sentence1, sentence2, sentence3, sentence4, sentence5, sentence6, sentence7]:\n",
    "    translation = \"\"\n",
    "    for word in sentence.split():\n",
    "        word = word.lower()\n",
    "        attachClosest(df, word)\n",
    "\n",
    "        translation += df.iloc[0][\"nl-simple\"] + \" \"\n",
    "    print(f\"source: {sentence} \\ntranslation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smarter translator\n",
    "\n",
    "word = \"kacho\"\n",
    "def distanceToWord(hide, seek):\n",
    "    max_search = len(seek)\n",
    "    distance = abs(len(hide)-len(seek))\n",
    "    if len(seek) > len(hide):\n",
    "        max_search = len(hide)\n",
    "    \n",
    "    for i in range(0, max_search):\n",
    "        if hide[i] != seek[i]:\n",
    "            distance += 1\n",
    "    return distance\n",
    "\n",
    "import unicodedata\n",
    "acc = \"kachó\"\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "print(remove_accents(acc))\n",
    "\n",
    "def attachClosest(df, word):\n",
    "    df[\"closest\"] = df.apply(lambda row: min(distanceToWord(remove_accents(row.name), word), distanceToWord(row.name, word)), axis=1)\n",
    "    df.sort_values(by=\"closest\", inplace= True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c6032c78efa7f90cd1715915e3f0102fff89cef77c12db36694d1cd45acba4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('luna-translate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
