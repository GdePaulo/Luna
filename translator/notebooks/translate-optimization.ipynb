{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../code'))\n",
    "import config\n",
    "from spellcheck import Spellcheck\n",
    "from util import Util\n",
    "\n",
    "# hny_pap_nl = pd.read_csv(\"../data/hny/pap-nl.csv\", na_filter=False)\n",
    "nbo_pap = pd.read_csv(\"../data/nbo/pap(cap).csv\", na_filter=False)\n",
    "corpus = Util.attachType(nbo_pap, \"pap-simple\")\n",
    "corpus = corpus[corpus[\"type\"]==\"word\"]\n",
    "words = corpus[\"pap-simple\"].values\n",
    "spell = Spellcheck(spellchecker_corpus=words)\n",
    "\n",
    "sentence = \"mi man no ta bon pero manan mi kuna ta trese anto bini bek\"\n",
    "big_sentence = \". Presidente di Banko Sentral di Kòrsou i St. Maarten sr. Richard Doornbosch... WILLEMSTAD.- Buskando solushon fo’i 2013 te ku 2019 pa Girobank, a hasi investigashon di e banko. A aserka APC i IIG TOF Holding N.V. (ámbos ta doño di Girobank ku respektivamente 42% i 58%) pa un plan di restrukturashon i re-kapitalisashon pa tin sufisiente kapital den e banko; identifiká potensial kumpradónan ku ke a invertí den e banko. Esaki no tabata algu fásil. Tabatin un défisit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "corpus_len = nbo_pap.copy()\n",
    "corpus_len[\"len\"] = nbo_pap.apply(lambda row: len(row[\"pap-simple\"]), axis=1)\n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "def screwWord(word):\n",
    "    screwed = word\n",
    "    \n",
    "    word_length = len(word)\n",
    "    for i in range(0, word_length):\n",
    "        screwed = screwed[:i] + screwed[random.randrange(0, word_length)] + screwed[i+1:]\n",
    "    return screwed\n",
    "\n",
    "\n",
    "# for word in four_raw:\n",
    "corpus_len[\"w\"] = corpus_len.apply(lambda row: screwWord(row[\"pap-simple\"]), axis=1)\n",
    "four_raw = corpus_len[corpus_len.len == 4]\n",
    "test_four = four_raw.head(10)[\"w\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate.getWordCorrections(sentence, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans.getFastWordCorrections(sentence, check_alternatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# trans.getMixedWordCorrections(sentence, corpus)\n",
    "smarter = \"iasabra el a bisami ekos kune i use\"\n",
    "# input_words = Util.findWords(big_sentence)\n",
    "input_words = test_four\n",
    "# print(input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.getMixedWordCorrections(input_words, corpus, \"Levenstein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.getMixedWordCorrections(input_words, corpus, metric=\"Hamming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.getWordCorrections(input_words, metric=\"Levenstein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremeFind(self, word, d):\n",
    "        found_word = \"\" \n",
    "        current = self\n",
    "        print(f\"word:{word} depth:{d}\")\n",
    "        for i, l in enumerate(word):\n",
    "\n",
    "            print(f\"index {i}\")\n",
    "            found_key = False\n",
    "            # print(f\"checking if {l} has accented\")\n",
    "            if d > 0 and l in current.children:\n",
    "                current = current.children[l]\n",
    "                found_word += l\n",
    "                print(f\"Appending letter {l}\")\n",
    "                found_key = True\n",
    "            elif d == 0:\n",
    "                print(f\"items are len {len(current.children.keys())}\")\n",
    "\n",
    "                for key, child in current.children.items():\n",
    "                    # print(f\"checking {accented_l}\")\n",
    "                    # print(f\"found {accented_l}\")\n",
    "                    rest_search = word[i+1:]\n",
    "\n",
    "                    print(f\"Word {word}, key {key}, ind {i}, d {d}\")\n",
    "                    print(f\"Checking {rest_search}\")\n",
    "                    found_rest_word = extremeFind(child, rest_search, d=d+1)\n",
    "                    print(f\"Found {found_rest_word}\")\n",
    "                    if found_rest_word:\n",
    "                        return key + found_rest_word\n",
    "                \n",
    "\n",
    "            if not found_key:\n",
    "                return \"\"\n",
    "            \n",
    "            if i == len(word)-1:\n",
    "                if current.lastNode:\n",
    "                    return found_word\n",
    "                else:\n",
    "                    return \"\"\n",
    "def getWordCorrections2(words):\n",
    "        translations = {}   \n",
    "        for word in words:\n",
    "            # Make sure to ignore case if you're making word lowercase\n",
    "            exists = spell.trie.find(word)\n",
    "            if not exists:\n",
    "                all_matches = extremeFind(spell.trie, word, d=0)\n",
    "                # matches = all_matches[:3]\n",
    "                return all_matches\n",
    "                # print(word, matches)\n",
    "                # if matches and matches[0][1] > 0:\n",
    "                if matches:\n",
    "                    # print(word, words_corpus.head(3)[\"closest\"].to_list())\n",
    "                    translations[word] = list(map(lambda x: x[0], matches))\n",
    "                elif not matches:\n",
    "                    translations[word] = [\"This word is incorrect\"]\n",
    "                \n",
    "        return translations\n",
    "# getWordCorrections2(input_words)\n",
    "getWordCorrections2([\"iopi\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters_test = \"(whatever)i don't know, but random. 15 a)e right {,age}()((er)\"\n",
    "characters_test = \"min sa 42% 32 fo'i ki dia re-kapitulashon M'a mire n' ta nothing' bai fo'i 'esaki tambe' 'gani sa?' e\"\n",
    "# characters_test = \"Buskando solushon fo’i 2013 te ku 2019\"\n",
    "import re\n",
    "def getWords(sentence):\n",
    "    # words = re.findall(r'^(.*?)[;\\.,!\\(].*',without_num)        \n",
    "    # words = re.findall(r'[^\\w\\d\\'](\\w+)[^\\w\\d\\']',sentence) \n",
    "    # words = re.findall(r'\\b([^\\d\\W]+[\\'-]?[^\\d\\W\\']*)\\b',sentence) \n",
    "    words = re.findall(r'\\b([^\\d\\W]+[\\'\\’-]*[^\\d\\W\\']*)',sentence) \n",
    "    # words = re.findall(r'\\b([\\d\\w\\'-]+)\\b',sentence) \n",
    "    # words = re.findall(r'([a-z]+[\\'-]?(?![\\w\\'-])[a-z]*)',sentence) \n",
    "    return words\n",
    "getWords(characters_test)\n",
    "# getWords(big_sentence)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c6032c78efa7f90cd1715915e3f0102fff89cef77c12db36694d1cd45acba4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('luna-translate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
