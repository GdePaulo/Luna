{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../code'))\n",
    "import config\n",
    "from spellcheck import Spellcheck\n",
    "from util import Util\n",
    "\n",
    "# hny_pap_nl = pd.read_csv(\"../data/hny/pap-nl.csv\", na_filter=False)\n",
    "nbo_pap = pd.read_csv(\"../data/nbo/pap(cap).csv\", na_filter=False)\n",
    "corpus = Util.attachType(nbo_pap, \"pap-simple\")\n",
    "corpus = corpus[corpus[\"type\"]==\"word\"]\n",
    "words = corpus[\"pap-simple\"].values\n",
    "spell = Spellcheck(spellchecker_corpus=words)\n",
    "\n",
    "sentence = \"mi man no ta bon pero manan mi kuna ta trese anto bini bek\"\n",
    "big_sentence = \". Presidente di Banko Sentral di Kòrsou i St. Maarten sr. Richard Doornbosch... WILLEMSTAD.- Buskando solushon fo’i 2013 te ku 2019 pa Girobank, a hasi investigashon di e banko. A aserka APC i IIG TOF Holding N.V. (ámbos ta doño di Girobank ku respektivamente 42% i 58%) pa un plan di restrukturashon i re-kapitalisashon pa tin sufisiente kapital den e banko; identifiká potensial kumpradónan ku ke a invertí den e banko. Esaki no tabata algu fásil. Tabatin un défisit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "corpus_len = nbo_pap.copy()\n",
    "corpus_len[\"len\"] = nbo_pap.apply(lambda row: len(row[\"pap-simple\"]), axis=1)\n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "def screwWord(word, screws=1):\n",
    "    screwed = word\n",
    "    \n",
    "    word_length = len(word)\n",
    "    for i in range(0, word_length):\n",
    "        if i < screws:\n",
    "            screwed = screwed[:i] + screwed[random.randrange(0, word_length)] + screwed[i+1:]\n",
    "    return screwed\n",
    "\n",
    "\n",
    "# for word in four_raw:\n",
    "corpus_len[\"w\"] = corpus_len.apply(lambda row: screwWord(row[\"pap-simple\"]), axis=1)\n",
    "four_raw = corpus_len[corpus_len.len == 4]\n",
    "test_four_original = four_raw.head(10)[\"pap-simple\"].values\n",
    "test_four = four_raw.head(10)[\"w\"].values\n",
    "print(test_four, test_four_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate.getWordCorrections(sentence, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans.getFastWordCorrections(sentence, check_alternatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# trans.getMixedWordCorrections(sentence, corpus)\n",
    "smarter = \"iasabra el a bisami ekos kune i use\"\n",
    "# input_words = Util.findWords(big_sentence)\n",
    "input_words = test_four\n",
    "# print(input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.getMixedWordCorrections(input_words, corpus, \"Levenstein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.getMixedWordCorrections(input_words, corpus, metric=\"Hamming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.getWordCorrections(input_words, metric=\"Levenstein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell.getPreSufCorrections(input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremeFind(self, word, d, errors=0):\n",
    "        found_word = \"\" \n",
    "        found_words = []\n",
    "        current = self\n",
    "        # print(f\"word:{word} depth:{d}\")\n",
    "        found_key = False\n",
    "\n",
    "        subs = False\n",
    "        dels = True\n",
    "        for i, l in enumerate(word):\n",
    "\n",
    "            # print(f\"index {i}\")\n",
    "            # print(f\"checking if {l} has accented\")\n",
    "            if d > 0:\n",
    "                if l in current.children:\n",
    "                    current = current.children[l]\n",
    "                    found_word += l\n",
    "                    print(f\"d > 0 appending letter {l} new found word {found_word}\")\n",
    "                    found_key = True\n",
    "                else:\n",
    "                    print(f\"d > 0 Didn't find {l}, children are {current.children}\")\n",
    "                    found_key = False\n",
    "            else:\n",
    "                print(f\"word:{word} depth:{d}\")\n",
    "                # print(f\"items are len {len(current.children.keys())}\")\n",
    "\n",
    "                if subs:\n",
    "                    for key, child in current.children.items():\n",
    "                        # print(f\"checking {accented_l}\")\n",
    "                        # print(f\"found {accented_l}\")\n",
    "                        rest_search = word[i+1:]\n",
    "\n",
    "                        print(f\"Checking {key} {rest_search}\")\n",
    "                        found_rest_words = extremeFind(child, rest_search, d=d+1)\n",
    "                        if found_rest_words:\n",
    "                            print(f\"Word {word}, key {key}, ind {i}, d {d}\")\n",
    "                            print(f\"Found {found_rest_words}\")\n",
    "                        if found_rest_words:\n",
    "                            found_words += [found_word + key + found_rest_word for found_rest_word in found_rest_words]\n",
    "                            print(f\"New found words {found_words}\")\n",
    "                            found_key = True\n",
    "                    \n",
    "                if l in current.children:\n",
    "                    old_root = current\n",
    "                    current = current.children[l]\n",
    "                    found_word += l\n",
    "                    print(f\"d:0 Appending letter {l} new found word {found_word}\")\n",
    "                    found_rest_words = extremeFind(old_root, word[i+1:], d=d+1)\n",
    "                    found_words += [found_rest_word for found_rest_word in found_rest_words]\n",
    "                    found_key = True\n",
    "                    if found_rest_words:\n",
    "                        print(f\"Searched {word[i+1:]} and found {found_words}\")\n",
    "                else:\n",
    "                    if i != len(word) - 1:\n",
    "                        found_rest_words = extremeFind(current, word[i+1], d=d+1)\n",
    "                        print(f\"{l} was not in children, I searched searched {word[i+1:]} and found {found_words}\")\n",
    "                        return found_rest_words\n",
    "\n",
    "            print(f\"d:{d} {word} letter {l} index {i} Last node? {current.lastNode} found key? {found_key}\")\n",
    "            if not found_key:\n",
    "                return found_words\n",
    "            \n",
    "            if i == len(word)-2 and d==0 and dels:\n",
    "                if current.lastNode:\n",
    "                    print(\"Appending to second to last\")\n",
    "                    found_words.append(found_word)\n",
    "                    return found_words\n",
    "\n",
    "            if i == len(word)-1:\n",
    "                if d == 0:\n",
    "                    print(f\"{word} {i} Last node? {current.lastNode}\")\n",
    "                if current.lastNode:\n",
    "                    found_words.append(found_word)\n",
    "                print(f\"Returning {found_words}\")\n",
    "                return found_words\n",
    "                # else:\n",
    "                #     return \"\"\n",
    "def getWordCorrections2(words):\n",
    "        translations = {}   \n",
    "        for word in words:\n",
    "            # Make sure to ignore case if you're making word lowercase\n",
    "            exists = spell.trie.find(word)\n",
    "            if not exists:\n",
    "                all_matches = extremeFind(spell.trie, word, d=0)\n",
    "                # matches = all_matches[:3]\n",
    "                # translations\n",
    "                # print(word, matches)\n",
    "                # if matches and matches[0][1] > 0:\n",
    "                if all_matches:\n",
    "                    # print(word, words_corpus.head(3)[\"closest\"].to_list())\n",
    "                    translations[word] = list(map(lambda x: x, all_matches))\n",
    "                # elif not matches:\n",
    "                #     translations[word] = [\"This word is incorrect\"]\n",
    "                \n",
    "        return translations\n",
    "# corr = getWordCorrections2(input_words)\n",
    "# corr = getWordCorrections2([\"tesa\"])\n",
    "corr = getWordCorrections2([\"mesd\", \"dmes\"])\n",
    "print(f\"Corrections: \", corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accentFind(self, word):\n",
    "    found_word = \"\" \n",
    "    found_words = []\n",
    "    current = self\n",
    "    print(f\"New accent find call for {word}\")\n",
    "    for i, l in enumerate(word):\n",
    "        found_key = False\n",
    "        # print(f\"Letter:{i}. checking if {l} has accented. Children {}\")\n",
    "        if l in self.accented:\n",
    "            for accented_l in self.accented[l]:\n",
    "                # print(f\"checking {accented_l}\")\n",
    "                if accented_l in current.children:\n",
    "\n",
    "                    print(f\"found {accented_l}\")\n",
    "                    accented_search = word[i+1:]\n",
    "                    if i == len(word) - 1:\n",
    "                        found_accented_words = [\"\"]\n",
    "                    else:\n",
    "                        found_accented_words = accentFind(current.children[accented_l], accented_search)\n",
    "                    print(f\"Returning from {accented_search} search with {found_accented_words}\")\n",
    "                    if found_accented_words:\n",
    "                        found_accented_words = [found_word + accented_l + x for x in found_accented_words]    \n",
    "                        found_words += found_accented_words\n",
    "            \n",
    "        if l in current.children:\n",
    "            current = current.children[l]\n",
    "            found_word += l\n",
    "            found_key = True\n",
    "            print(f\"Search {word}. I found {l} as a key. Total word is {found_word}\")\n",
    "\n",
    "        if not found_key:\n",
    "            return found_words\n",
    "        \n",
    "        if i == len(word)-1:\n",
    "            if current.lastNode:\n",
    "                found_words.append(found_word)\n",
    "            return found_words\n",
    "accent_words = [\"paga\", \"post\", \"korsou\", \"minut\", \"don'texist\", \"kòrsou\", \"korsòu\", \"bon\", \"no\"]            \n",
    "accentFind(spell.trie, accent_words[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters_test = \"(whatever)i don't know, but random. 15 a)e right {,age}()((er)\"\n",
    "characters_test = \"min sa 42% 32 fo'i ki dia re-kapitulashon M'a mire n' ta nothing' bai fo'i 'esaki tambe' 'gani sa?' e\"\n",
    "# characters_test = \"Buskando solushon fo’i 2013 te ku 2019\"\n",
    "import re\n",
    "def getWords(sentence):\n",
    "    # words = re.findall(r'^(.*?)[;\\.,!\\(].*',without_num)        \n",
    "    # words = re.findall(r'[^\\w\\d\\'](\\w+)[^\\w\\d\\']',sentence) \n",
    "    # words = re.findall(r'\\b([^\\d\\W]+[\\'-]?[^\\d\\W\\']*)\\b',sentence) \n",
    "    words = re.findall(r'\\b([^\\d\\W]+[\\'\\’-]*[^\\d\\W\\']*)',sentence) \n",
    "    # words = re.findall(r'\\b([\\d\\w\\'-]+)\\b',sentence) \n",
    "    # words = re.findall(r'([a-z]+[\\'-]?(?![\\w\\'-])[a-z]*)',sentence) \n",
    "    return words\n",
    "getWords(characters_test)\n",
    "# getWords(big_sentence)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c6032c78efa7f90cd1715915e3f0102fff89cef77c12db36694d1cd45acba4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('luna-translate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
